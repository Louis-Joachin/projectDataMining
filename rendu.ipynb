{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import tree\n",
    "import operator\n",
    "import random\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partie Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a précedemment créé les différents labels pour chaque tableau, initialisé les différents utilisateurs. On peut maintenant analyser les donnés et en déduire d'autres informations qui nous serviront à faire les recommandations pour les utilisateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ouverture des fichiers précédemment créés\n",
    "with open(\"label.json\",'r') as jsonTab:\n",
    "    dataTab = json.load(jsonTab)\n",
    "dataframeTab = json_normalize(dataTab)\n",
    "\n",
    "with open(\"user.json\",'r') as jsonUser:\n",
    "    dataUser = json.load(jsonUser)\n",
    "dataframeUser = json_normalize(dataUser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(input(\"Vous souhaiter visualiser les données de l'utilisateur n° ? (entre 0 et 99)\"))\n",
    "if n not in range(99):\n",
    "    print(\"Nombre invalide, le script va sûrement planter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par déterminer la couleur dominante de chaque tableaux, qui va nous permettre de réaliser une recommandation précise pour chaque utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#détermination des couleurs et des formats préférés de l'utilisateur en fonction des likes\n",
    "couleursPref = []\n",
    "listeFormat = []\n",
    "compteFormat = []\n",
    "#récupération des couleurs dominantes des tableaux likés par l'utilisateur 0\n",
    "for tab in dataTab:\n",
    "    if tab['lien'] in dataUser[n]['likes']:\n",
    "        couleursPref.append(tab['couleur'])\n",
    "        format = tab['format']\n",
    "        if format in listeFormat:\n",
    "            compteFormat[listeFormat.index(format)]+=1\n",
    "        else:\n",
    "            compteFormat.append(1)\n",
    "            listeFormat.append(format)\n",
    "\n",
    "formatPref=listeFormat[compteFormat.index(max(compteFormat))]\n",
    "dataUser[n]['formatPref']=formatPref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise une fonction KMeans car une moyenne de toutes les couleurs résulterait en une couleur moyenne ~=[122,122,122]. On utilise après un histogramme pour classer les couleurs, et obtenir la couleur qui est la plus représentée sur l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#partitionement des couleurs dominantes de tous les tableaux en 3 cluster\n",
    "couleursPref = MiniBatchKMeans(3).fit(couleursPref)\n",
    "#création d'un numpyarray\n",
    "npbins = numpy.arange(0, 4)\n",
    "#création d'un histogramme qui classe les clusters par odre croissant\n",
    "histogram = numpy.histogram(couleursPref.labels_, bins=npbins)\n",
    "imax = numpy.argmax(histogram[0])\n",
    "\n",
    "R = math.ceil(couleursPref.cluster_centers_[imax][0])\n",
    "G = math.ceil(couleursPref.cluster_centers_[imax][1])\n",
    "B = math.ceil(couleursPref.cluster_centers_[imax][2])\n",
    "\n",
    "dataUser[n]['couleurPref']=[R,G,B]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On détermine également le tag préféré de chaque utilisateur, afin de pouvoir lui recommander un tableau qui lui corresponde au mieux.<br>\n",
    "On écrit ensuite ces changements dans le fichier JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#détermination du tag préféré de l'utilsateur\n",
    "listeTag=[]\n",
    "compteTag=[]\n",
    "for tableau in dataUser[n]['tags']:\n",
    "    tag=dataUser[n]['tags'][tableau]\n",
    "    if tag in listeTag:\n",
    "        compteTag[listeTag.index(tag)]+=1\n",
    "    else:\n",
    "        compteTag.append(1)\n",
    "        listeTag.append(tag)\n",
    "\n",
    "tagPref=listeTag[compteTag.index(max(compteTag))]\n",
    "dataUser[n]['tagPref']=tagPref\n",
    "\n",
    "\n",
    "jsonUser=open(\"user.json\",'w')\n",
    "jsonUser.write(json.dumps(dataUser, ensure_ascii=False))\n",
    "jsonUser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partie Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pour pouvoir visualiser les données, et réaliser des classifications on utilise les dataframes de la bibliothèque pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par créer les différents dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"label.json\",'r') as jsonTab:\n",
    "    dataTab = json.load(jsonTab)\n",
    "dataframeTab = json_normalize(dataTab)\n",
    "\n",
    "with open(\"user.json\",'r') as jsonUser:\n",
    "    dataUser = json.load(jsonUser)\n",
    "dataframeUser = json_normalize(dataUser)\n",
    "\n",
    "arrayAuteur = []\n",
    "arrayFormat = []\n",
    "arrayLikes = []\n",
    "arrayCouleur = []\n",
    "for data in dataTab :\n",
    "    arrayAuteur.append([data['auteur'],data['lien']])\n",
    "    arrayFormat.append([data['format'],data['lien']])\n",
    "    arrayLikes.append([data['likes'],data['lien']])\n",
    "    arrayCouleur.append(data['couleur'])\n",
    "dataframeAuteur = pd.DataFrame(arrayAuteur, columns=['auteur','lien'])\n",
    "dataframeFormat = pd.DataFrame(arrayFormat, columns=['format','lien'])\n",
    "dataframeLikes = pd.DataFrame(arrayLikes, columns=['likes','lien'])\n",
    "couleursDom = pd.DataFrame(arrayCouleur, columns=['R','G','B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On réalise les différents groupby afin d'obtenir les différentes données à utiliser : nombre de tableaux par auteur, par format et par likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped=dataframeAuteur.groupby(\"auteur\").count()\n",
    "grouped = grouped.rename(\n",
    "    columns={'lien':'count'}).reset_index()\n",
    "\n",
    "grouped2 = dataframeFormat.groupby(\"format\").count()\n",
    "grouped2 = grouped2.rename(\n",
    "    columns={'lien':'count'}).reset_index()\n",
    "\n",
    "grouped3 = dataframeLikes.groupby(\"likes\").count()\n",
    "grouped3 = grouped3.rename(\n",
    "    columns={'lien':'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On représente ensuite les couleurs les plus représentées dans nos tableaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbcluster = 5\n",
    "clusters = MiniBatchKMeans(nbcluster).fit(couleursDom)\n",
    "#création d'un numpyarray\n",
    "npbins = numpy.arange(0, nbcluster + 1)\n",
    "#création d'un histogramme qui classe les clusters par odre croissant\n",
    "histogram = numpy.histogram(clusters.labels_, bins=npbins)\n",
    "labels = numpy.unique(clusters.labels_)\n",
    "\n",
    "histogram[0][::-1].sort() #permet d'inverser le tri (ordre décroissant)\n",
    "\n",
    "colors = []\n",
    "for i in range(nbcluster):\n",
    "    colors.append('#%02x%02x%02x' % (\n",
    "    math.ceil(clusters.cluster_centers_[i][0]), \n",
    "        math.ceil(clusters.cluster_centers_[i][1]),\n",
    "    math.ceil(clusters.cluster_centers_[i][2])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche maintenant les différents éléments : un 'pie chart' pour représenter les couleurs, et des diagrammes batons pour les informations sur les labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(histogram[0],labels=labels, autopct='%1.1f%%', startangle=90, colors=colors) #autopct permet d'avoir des pourcentages\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "grouped.plot(x=0, kind='bar', title=\"Nombre de tableaux par auteur\")\n",
    "grouped2.plot(x=0, kind='bar', title=\"Nombre de tableaux par format\")\n",
    "grouped3.plot(x=0, kind='bar', title=\"Nombre de tableaux par likes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partie Recommandation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On réalise les recommandations pour les utilisateurs. On a choisi de faire les recommandations pour l'utilisateur 0, mais on pourrait le réaliser pour n'importe quel utilisateur de notre base de doonnées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée une fonction comparaison couleur, que nous utiliserons pour chercher si deux couleurs sont proches ou non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction de comparaison de couleurs\n",
    "#Entrées : deux codes RGB de deux couleurs\n",
    "#Sorties : un indice de proximité des couleurs\n",
    "def ComparaisonCouleur(couleur1, couleur2):\n",
    "    dif = []\n",
    "    for i in range (3):\n",
    "        dif.append(couleur1[i] - couleur2[i])\n",
    "    #mise au carré pour être sûr d'avoir des valeurs de diférence positive \n",
    "    return dif[0]**2+dif[1]**2+dif[2]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée ensuite les dataframes que nous donnerons à notre algorithme de classification. On crée donc deux dataframes : celui avec les tableaux (on mettra les différents paramètres de comparaison : auteur, format et tag le plus utilisé). Le dataframe result sera composé de 1 (le tableau a été liké) et de -1 (le tableau a été vu mais non liké)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "result=[]\n",
    "auteur_vu=[]\n",
    "dataTabCustom = dataTab #on crée une copie de notre liste de tableaux, qui représentera les tableaux \"non vus\" par l'utilisateur\n",
    "for lien in dataUser[n][\"likes\"]: #on construit un dataframe qui va servir à l'algo de classification : on commence par les tableaux likés par l'utilisateur (result = 1)\n",
    "    for tableau in dataTab:\n",
    "        if lien == tableau[\"lien\"]:\n",
    "            tag = max(tableau[\"tags\"].items(), key=operator.itemgetter(1))[0] #l'algo ne prend pas de liste de tags en paramètre: on choisit donc le tag le plus utilisé sur le tableau\n",
    "            data.append([tableau[\"auteur\"],tableau[\"format\"],tag])\n",
    "            result.append(1)\n",
    "            auteur_vu.append(tableau[\"auteur\"])\n",
    "            dataTabCustom.remove(tableau)\n",
    "            \n",
    "\n",
    "for lien in dataUser[n][\"unlikes\"]:#on fait la même chose avec les tableaux vu et non likés (result = -1)\n",
    "    for tableau in dataTab:\n",
    "        if lien == tableau[\"lien\"]:\n",
    "            tag = max(tableau[\"tags\"].items(), key=operator.itemgetter(1))[0]\n",
    "            data.append([tableau[\"auteur\"],tableau[\"format\"],tag])\n",
    "            result.append(-1)\n",
    "            auteur_vu.append(tableau[\"auteur\"])\n",
    "            dataTabCustom.remove(tableau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On lance maintenant notre algorithme de classification : on utilise l'algorithme DecisionTreeClasifier, qui nous permetttra de réaliser des prédictions (l'utilisateur va aimer ou non le tableau).\n",
    "On commence par encoder les labels pour que l'algorithme puisse les comprendre, puis on fourni les dataframes à l'algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(data, columns=['auteur', 'format', 'tags'])#construction des dataframes\n",
    "resultframe = pd.DataFrame(result, columns=['like'])\n",
    "\n",
    "le1 = LabelEncoder() #encodage des labels\n",
    "dataframe['auteur'] = le1.fit_transform(dataframe['auteur'])\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "dataframe['format'] = le2.fit_transform(dataframe['format'])\n",
    "\n",
    "le3 = LabelEncoder()\n",
    "dataframe['tags'] = le3.fit_transform(dataframe['tags'])\n",
    "\n",
    "le4 = LabelEncoder()\n",
    "resultframe['like'] = le4.fit_transform(resultframe['like'])\n",
    "\n",
    "#On utilise les classifieurs \"arbres\"\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "dtc = dtc.fit(dataframe, resultframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On réalise maintenant des recommandations jusqu'à avoir 10 recommandations à faire à l'utilisateur. On a supprimé les warnings généré par l'algorithme grâce aux deux premièress lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "recommandation = [] #on initialise une liste de tableaux recommandés\n",
    "non_recommandation=[] #on initialise une liste de tableaux non-recommandés\n",
    "while len(recommandation)<10 and len(dataTabCustom)>0:\n",
    "    tab = random.choice(dataTabCustom)\n",
    "    if tab[\"auteur\"] not in auteur_vu: #l'algo de prédiction plante si on lui présente un tableau dont l'auteur est n'a pas été vu par l'utilisateur.\n",
    "        continue\n",
    "    prediction = dtc.predict([ #on réalise une prédiction pour savoir si le tableau plaira à l'utilisateur\n",
    "            [le1.transform([tab[\"auteur\"]])[0], le2.transform([tab[\"format\"]])[0],\n",
    "            le3.transform([max(tableau[\"tags\"].items(), key=operator.itemgetter(1))[0]])[0]]])\n",
    "    if prediction == 1: \n",
    "        recommandation.append(tab)\n",
    "    else:\n",
    "        non_recommandation.append(tab)\n",
    "    dataTabCustom.remove(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On rajoute maintenant le paramètre de la couleur, afin de pouvoir proposer à l'utilisateur le tableau dont la couleur dominante est la plus proche de sa couleur préférée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tab in recommandation: #on ajoute une comparaison par couleurs des tableaux, afin d'avoir la recommandation la plus précise possible\n",
    "    tab[\"indice_couleur\"]=ComparaisonCouleur(dataUser[n][\"couleurPref\"],tab[\"couleur\"])\n",
    "\n",
    "dataframe=pd.DataFrame(recommandation)\n",
    "dataframe.drop(columns=[\"auteur\",'largeur','hauteur','format','tags','unlikes','couleur'],inplace=True)\n",
    "dataframe.sort_values(by=\"indice_couleur\",inplace=True)\n",
    "if dataframe.iloc[0]['indice_couleur']>200 :\n",
    "    dataframe.sort_values(by=\"likes\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affichage des recommandations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les images likés de l'utilisateur, puis les recommandations que nous pouvons faire grâce aux algorithmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Images likés')\n",
    "for i in range(len(dataUser[n][\"likes\"])):\n",
    "    img = mpimg.imread(dataUser[n][\"likes\"][i])\n",
    "    imgplot=plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Notre recommandation : ')\n",
    "img = mpimg.imread(dataframe.iloc[0]['lien'])\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Les tableaux qui pourraient aussi vous plaire : \")\n",
    "for i in range(9):\n",
    "    img = mpimg.imread(dataframe.iloc[i+1]['lien'])\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc124f305ac09517833dfcf876565d4ea14a0f9adcd6fcb2efd0e812a46b255d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
